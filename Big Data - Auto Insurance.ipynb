{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read traning data\n",
    "df = pd.read_csv(\"training_data.csv\", low_memory=False)\n",
    "start_index = list(df.columns).index('Claim_Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d3d43beead43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Loss_Amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avg' is not defined"
     ]
    }
   ],
   "source": [
    "target = df['Loss_Amount']\n",
    "df = df.drop(df.columns[start_index:], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import copy\n",
    "\n",
    "def drop_unknown(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def label_encode(df):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in df.columns:\n",
    "        col = str(col)\n",
    "        if str(df.loc[:,col].dtype) == 'object':\n",
    "            le.fit(df.loc[:,col]) \n",
    "            df.loc[:,col] = le.transform(df.loc[:,col])\n",
    "    return df\n",
    "\n",
    "def clean_data(df, missing_handler=drop_unknown, data_encoder=label_encode):\n",
    "    df = missing_handler(df)\n",
    "    return data_encoder(df)\n",
    "\n",
    "def pca(df, num_components):\n",
    "    pca = PCA(num_components).fit(df)\n",
    "    principal_cols = pca.transform(df)\n",
    "    return pd.DataFrame(data = principal_cols)\n",
    "    \n",
    "\n",
    "def preprocess_data(df, **params):\n",
    "    \"\"\"\n",
    "    Preprocesses dataframe, with customizable options.\n",
    "    \n",
    "    params:\n",
    "        dropped_columns[list]: list of columns to be dropped before preprocessing begins.\n",
    "    \n",
    "        clean[Boolean]: should the data be cleaned.\n",
    "        \n",
    "        missing_handler[function(dataframe) returns dataframe]: how to handle missing data,\n",
    "                       'dropna' by default.\n",
    "                                             \n",
    "        data_encoder[function(dataframe) returns dataframe]: specifies encoder for data, \n",
    "                    'label encoding' is the default.\n",
    "        \n",
    "        feature_transform[Boolean]: does feature transformation need to be performed.\n",
    "        \n",
    "        feature_transformer[function(dataframe) returns dataframe]: specifies the feature transformer,\n",
    "                        'Standardization' is the default.\n",
    "                                          \n",
    "        feature_selection[Boolean]: does feature selection need to be performed.\n",
    "        \n",
    "        feature_selector[function(dataframe) returns dataframe]: specifies the feature selector,\n",
    "                        'PCA' is the default.\n",
    "                        \n",
    "        num_components[int]: specifies the number of principal components we want.\n",
    "                                 Default is 30 components.\n",
    "        \n",
    "    NOTE: all boolean params are set to 'False' by default.\n",
    "          So the call 'preprocessor()' does nothing, because no arguments are passed.\n",
    "    \"\"\"\n",
    "    drop_cols = params.get('dropped_columns', [])\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    do_clean = params.get('clean', False)\n",
    "    if do_clean:\n",
    "        missing_handler = params.get('missing_handler', drop_unknown)\n",
    "        data_encoder = params.get('data_encoder', label_encode)\n",
    "        df = clean_data(df, missing_handler, data_encoder)\n",
    "    \n",
    "    do_transform = params.get('feature_transform', False)\n",
    "    if do_transform:\n",
    "        transformer = params.get('feature_transformer', StandardScaler().fit_transform)\n",
    "        scaled_features = transformer(df)\n",
    "        df = pd.DataFrame(scaled_features, index=df.index, columns=df.columns)\n",
    "        \n",
    "    do_feature_selection = params.get('feature_selection', False)\n",
    "    num_components = params.get('num_components', 30)\n",
    "    if do_feature_selection:\n",
    "        feature_selector = params.get('feature_selector', pca)\n",
    "        df = feature_selector(df, num_components)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rishant96/Documents/Python/BigData/env_ds/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.785450</td>\n",
       "      <td>-3.209023</td>\n",
       "      <td>3.674657</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>-0.123389</td>\n",
       "      <td>-0.351678</td>\n",
       "      <td>-1.078479</td>\n",
       "      <td>0.355020</td>\n",
       "      <td>-1.613381</td>\n",
       "      <td>0.557680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473379</td>\n",
       "      <td>0.215753</td>\n",
       "      <td>0.435169</td>\n",
       "      <td>0.888003</td>\n",
       "      <td>-0.139465</td>\n",
       "      <td>0.126721</td>\n",
       "      <td>0.467495</td>\n",
       "      <td>-0.373731</td>\n",
       "      <td>0.669415</td>\n",
       "      <td>0.102986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.402349</td>\n",
       "      <td>-3.605650</td>\n",
       "      <td>3.758536</td>\n",
       "      <td>2.903636</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>-1.741795</td>\n",
       "      <td>-2.083471</td>\n",
       "      <td>2.408650</td>\n",
       "      <td>1.336873</td>\n",
       "      <td>6.600749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.834658</td>\n",
       "      <td>0.090615</td>\n",
       "      <td>0.834899</td>\n",
       "      <td>1.391255</td>\n",
       "      <td>-0.622428</td>\n",
       "      <td>-0.235271</td>\n",
       "      <td>-1.643442</td>\n",
       "      <td>-0.533840</td>\n",
       "      <td>-0.118106</td>\n",
       "      <td>0.420246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.913796</td>\n",
       "      <td>-3.951205</td>\n",
       "      <td>3.648198</td>\n",
       "      <td>1.581371</td>\n",
       "      <td>-0.020146</td>\n",
       "      <td>1.205139</td>\n",
       "      <td>-2.307780</td>\n",
       "      <td>1.610967</td>\n",
       "      <td>-1.452347</td>\n",
       "      <td>2.427298</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.559137</td>\n",
       "      <td>0.408827</td>\n",
       "      <td>1.502663</td>\n",
       "      <td>2.234458</td>\n",
       "      <td>-0.750039</td>\n",
       "      <td>-0.503332</td>\n",
       "      <td>1.097267</td>\n",
       "      <td>-0.882805</td>\n",
       "      <td>-1.433142</td>\n",
       "      <td>0.217913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.058758</td>\n",
       "      <td>-3.631684</td>\n",
       "      <td>2.589896</td>\n",
       "      <td>1.154251</td>\n",
       "      <td>-0.040150</td>\n",
       "      <td>0.287273</td>\n",
       "      <td>-3.239068</td>\n",
       "      <td>2.394210</td>\n",
       "      <td>1.192992</td>\n",
       "      <td>0.813500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.900659</td>\n",
       "      <td>-0.167007</td>\n",
       "      <td>1.325234</td>\n",
       "      <td>2.076389</td>\n",
       "      <td>-1.117896</td>\n",
       "      <td>-0.030729</td>\n",
       "      <td>0.776766</td>\n",
       "      <td>-0.745942</td>\n",
       "      <td>-1.501702</td>\n",
       "      <td>0.018583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043411</td>\n",
       "      <td>-3.684705</td>\n",
       "      <td>2.623003</td>\n",
       "      <td>1.178389</td>\n",
       "      <td>-0.037333</td>\n",
       "      <td>0.286129</td>\n",
       "      <td>-3.256346</td>\n",
       "      <td>2.405084</td>\n",
       "      <td>1.179504</td>\n",
       "      <td>0.825138</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.909805</td>\n",
       "      <td>-0.178503</td>\n",
       "      <td>1.335868</td>\n",
       "      <td>2.092105</td>\n",
       "      <td>-1.148585</td>\n",
       "      <td>-0.032050</td>\n",
       "      <td>0.778184</td>\n",
       "      <td>-0.747565</td>\n",
       "      <td>-1.517703</td>\n",
       "      <td>0.025968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407100</th>\n",
       "      <td>2.228527</td>\n",
       "      <td>6.141460</td>\n",
       "      <td>1.818947</td>\n",
       "      <td>0.529052</td>\n",
       "      <td>-0.394539</td>\n",
       "      <td>1.196978</td>\n",
       "      <td>-1.041689</td>\n",
       "      <td>-0.080872</td>\n",
       "      <td>0.786084</td>\n",
       "      <td>-0.629960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292738</td>\n",
       "      <td>-1.096991</td>\n",
       "      <td>1.615012</td>\n",
       "      <td>-1.080812</td>\n",
       "      <td>-0.221830</td>\n",
       "      <td>0.346417</td>\n",
       "      <td>-0.739242</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>-0.369013</td>\n",
       "      <td>1.771514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407101</th>\n",
       "      <td>4.070448</td>\n",
       "      <td>0.465518</td>\n",
       "      <td>-0.851061</td>\n",
       "      <td>-2.137626</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>4.615673</td>\n",
       "      <td>-1.363630</td>\n",
       "      <td>-6.618264</td>\n",
       "      <td>1.866449</td>\n",
       "      <td>2.352853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.491736</td>\n",
       "      <td>-0.097001</td>\n",
       "      <td>0.283760</td>\n",
       "      <td>0.279784</td>\n",
       "      <td>-0.415981</td>\n",
       "      <td>-0.371176</td>\n",
       "      <td>2.148225</td>\n",
       "      <td>-0.083990</td>\n",
       "      <td>-0.686483</td>\n",
       "      <td>0.658414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407102</th>\n",
       "      <td>-0.747832</td>\n",
       "      <td>6.652316</td>\n",
       "      <td>2.363396</td>\n",
       "      <td>2.077997</td>\n",
       "      <td>-0.546127</td>\n",
       "      <td>-0.391419</td>\n",
       "      <td>1.419286</td>\n",
       "      <td>-0.815882</td>\n",
       "      <td>0.201909</td>\n",
       "      <td>0.336397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548651</td>\n",
       "      <td>-1.202113</td>\n",
       "      <td>1.914405</td>\n",
       "      <td>-1.051068</td>\n",
       "      <td>-0.163129</td>\n",
       "      <td>-1.086661</td>\n",
       "      <td>1.184296</td>\n",
       "      <td>-1.342895</td>\n",
       "      <td>0.480556</td>\n",
       "      <td>1.343198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407103</th>\n",
       "      <td>0.189861</td>\n",
       "      <td>-1.050174</td>\n",
       "      <td>0.583332</td>\n",
       "      <td>-0.578568</td>\n",
       "      <td>0.049488</td>\n",
       "      <td>1.831582</td>\n",
       "      <td>0.400301</td>\n",
       "      <td>-1.530487</td>\n",
       "      <td>-0.942854</td>\n",
       "      <td>-2.739093</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.702581</td>\n",
       "      <td>0.176425</td>\n",
       "      <td>0.278666</td>\n",
       "      <td>0.277866</td>\n",
       "      <td>-0.601770</td>\n",
       "      <td>-0.885833</td>\n",
       "      <td>0.521046</td>\n",
       "      <td>1.518777</td>\n",
       "      <td>-0.459026</td>\n",
       "      <td>0.182170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407104</th>\n",
       "      <td>-1.931319</td>\n",
       "      <td>1.825085</td>\n",
       "      <td>-1.148416</td>\n",
       "      <td>-2.737553</td>\n",
       "      <td>0.166089</td>\n",
       "      <td>-2.121208</td>\n",
       "      <td>-0.575200</td>\n",
       "      <td>-2.013131</td>\n",
       "      <td>-0.394970</td>\n",
       "      <td>-1.755790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172888</td>\n",
       "      <td>-0.236408</td>\n",
       "      <td>0.974226</td>\n",
       "      <td>1.290426</td>\n",
       "      <td>-0.481797</td>\n",
       "      <td>-0.339737</td>\n",
       "      <td>-0.683230</td>\n",
       "      <td>0.445520</td>\n",
       "      <td>-0.121651</td>\n",
       "      <td>0.273044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407105 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       0.785450 -3.209023  3.674657  0.708684 -0.123389 -0.351678 -1.078479   \n",
       "1      -2.402349 -3.605650  3.758536  2.903636  0.004053 -1.741795 -2.083471   \n",
       "2       0.913796 -3.951205  3.648198  1.581371 -0.020146  1.205139 -2.307780   \n",
       "3       1.058758 -3.631684  2.589896  1.154251 -0.040150  0.287273 -3.239068   \n",
       "4       1.043411 -3.684705  2.623003  1.178389 -0.037333  0.286129 -3.256346   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "407100  2.228527  6.141460  1.818947  0.529052 -0.394539  1.196978 -1.041689   \n",
       "407101  4.070448  0.465518 -0.851061 -2.137626  0.040404  4.615673 -1.363630   \n",
       "407102 -0.747832  6.652316  2.363396  2.077997 -0.546127 -0.391419  1.419286   \n",
       "407103  0.189861 -1.050174  0.583332 -0.578568  0.049488  1.831582  0.400301   \n",
       "407104 -1.931319  1.825085 -1.148416 -2.737553  0.166089 -2.121208 -0.575200   \n",
       "\n",
       "              7         8         9   ...        34        35        36  \\\n",
       "0       0.355020 -1.613381  0.557680  ...  1.473379  0.215753  0.435169   \n",
       "1       2.408650  1.336873  6.600749  ... -0.834658  0.090615  0.834899   \n",
       "2       1.610967 -1.452347  2.427298  ... -3.559137  0.408827  1.502663   \n",
       "3       2.394210  1.192992  0.813500  ... -0.900659 -0.167007  1.325234   \n",
       "4       2.405084  1.179504  0.825138  ... -0.909805 -0.178503  1.335868   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "407100 -0.080872  0.786084 -0.629960  ... -0.292738 -1.096991  1.615012   \n",
       "407101 -6.618264  1.866449  2.352853  ... -0.491736 -0.097001  0.283760   \n",
       "407102 -0.815882  0.201909  0.336397  ...  0.548651 -1.202113  1.914405   \n",
       "407103 -1.530487 -0.942854 -2.739093  ... -3.702581  0.176425  0.278666   \n",
       "407104 -2.013131 -0.394970 -1.755790  ...  0.172888 -0.236408  0.974226   \n",
       "\n",
       "              37        38        39        40        41        42        43  \n",
       "0       0.888003 -0.139465  0.126721  0.467495 -0.373731  0.669415  0.102986  \n",
       "1       1.391255 -0.622428 -0.235271 -1.643442 -0.533840 -0.118106  0.420246  \n",
       "2       2.234458 -0.750039 -0.503332  1.097267 -0.882805 -1.433142  0.217913  \n",
       "3       2.076389 -1.117896 -0.030729  0.776766 -0.745942 -1.501702  0.018583  \n",
       "4       2.092105 -1.148585 -0.032050  0.778184 -0.747565 -1.517703  0.025968  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "407100 -1.080812 -0.221830  0.346417 -0.739242  0.012085 -0.369013  1.771514  \n",
       "407101  0.279784 -0.415981 -0.371176  2.148225 -0.083990 -0.686483  0.658414  \n",
       "407102 -1.051068 -0.163129 -1.086661  1.184296 -1.342895  0.480556  1.343198  \n",
       "407103  0.277866 -0.601770 -0.885833  0.521046  1.518777 -0.459026  0.182170  \n",
       "407104  1.290426 -0.481797 -0.339737 -0.683230  0.445520 -0.121651  0.273044  \n",
       "\n",
       "[407105 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = preprocess_data(df, dropped_columns=['PolicyNo'], clean=True, feature_transform=True,\n",
    "                           feature_selection=True)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
